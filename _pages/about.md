---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I am a researcher at the [Artificial Intelligence Research Center](https://www.iiia.csic.es/en-us/), a research center
associated to the [Spanish National Research Council](https://www.csic.es/en/csic). Previously, I was awarded a Marie 
Curie Career Fit PLUS Fellow to conduct research on adversarial attacks and defenses against malware detectors.
More information about the award can be found in [Horizon Europe's webpage.](https://horizoneurope.ie/career-fit-plus). 
The research project was conducted in collaboration with [CeADAR.](https://ceadar.ie/) and [IBM's AI Security and Data Privacy Group](https://research.ibm.com/labs/ireland/).

I received my PhD in Engineering and Information Technologies from the University of Lleida. 
In 2016, I received my Master’s in Artificial Intelligence from the Polytechnic University of Catalonia.
My thesis focused on the design, implementation, and evaluation of ML-based approaches for the task of malware detection
and classification.
					
Research
======
My main area of research lies at the intersection of Machine Learning (ML) and Information Security. 
My work has focused on building, attacking, and defending malware detectors using a wide range of statistical learning theories,
including Machine Learning, Deep Learning, Transfer Learning, Adversarial Learning, and Deep Reinforcement Learning.

I have recently been awarded a Ramón y Cajal Fellowship to conduct research on the robustness and explainability of 
Artificial Intelligence (AI) systems. With AI increasingly integrated into decision-making processes and autonomous systems,
the challenges posed by its use in an ever-increasing number of areas have serious implications for citizens and organizations,
as recognized by the EU AI Act. Despite their performances, AI systems are not yet considered as reliable enough 
to be fully autonomous in complex environments without human supervision. Beyond the classical software vulnerabilities 
that are inherent to any piece of software, AI systems open up new surfaces of vulnerabilities, many of which remain 
largely unexplored outside the Computer Vision domain. Addressing these challenges is pivotal for deploying secure and 
dependable AI systems, particularly in high-risk scenarios.

Recent News
======
* October, 2024. A preprint version of our paper [Assessing the Impact of Packing on Machine Learning-Based Malware Detection and Classification Systems](https://arxiv.org/abs/2410.24017) is available at ArXiv.
* May, 2024. An extended version of the AISEC's paper has been published at ArXiv. The paper titled [Certified Adversarial Robustness of Machine Learning-based Malware Detectors via (De)Randomized Smoothing](https://arxiv.org/abs/2405.00392) presents a certified defense against patch and content injection attacks for end-to-end malware detectors."
* April, 2024. Book chapter titled [Machine Learning for Windows Malware Detection and Classification: Methods, Challenges and Ongoing Research](https://arxiv.org/abs/2404.18541) has been published at ArXiv. This chapter will appear at the book "https://link.springer.com/book/9783031662447" published by Springer.
* April, 2024. The paper titled [Adversarial Robustness of Deep Learning-Based Malware Detectors via (De)Randomized Smoothing](https://ieeexplore.ieee.org/document/10506708) has been published at IEE Access.